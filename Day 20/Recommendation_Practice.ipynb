{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=title>\n",
    "<strong><center><font size=\"3\">DAY 20 - IYKRA</font></center>\n",
    "<hr>\n",
    "<center><font size=\"5\"><strong>Data Science Bootcamp</strong></font></center>\n",
    "<center><font size=\"4\"><strong>Applied Machine Learning: Marketing</strong></font></center>\n",
    "<hr>\n",
    "<p style=\"text-align:center\">Author</p>\n",
    "<center>Joshua Effendi</center>\n",
    "<p style=\"text-align:center\">Date:</p>\n",
    "<center>15 November 2019</center></strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T04:43:50.238000Z",
     "start_time": "2019-11-15T04:43:50.216000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.cbox {\n",
       "    background-color: #ADD8E6;\n",
       "    padding: 0.5em;\n",
       "    text-align: justify;\n",
       "    text-justify: inter-word;\n",
       "    }\n",
       "div.title {\n",
       "    background-color: #90EE90;\n",
       "    padding: 0.5em;\n",
       "    }\n",
       "div.title2 {\n",
       "    background-color: #01D848;\n",
       "    padding: 0.5em;\n",
       "    }\n",
       "div.title1 {\n",
       "    background-color: #AADDAA;\n",
       "    padding: 0.5em;\n",
       "    }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"./styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=title1>\n",
    "    <b><font size='4'>Apriori</font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T04:39:52.636000Z",
     "start_time": "2019-11-15T04:39:52.629000Z"
    }
   },
   "source": [
    "<div class=title2>\n",
    "    <b><font size='3'>Import Libraries</font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T04:41:07.501000Z",
     "start_time": "2019-11-15T04:41:07.494000Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T04:43:54.680000Z",
     "start_time": "2019-11-15T04:43:54.670000Z"
    }
   },
   "source": [
    "<div class=title2>\n",
    "    <b><font size='3'>Define Apriori Class</font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T04:41:19.459000Z",
     "start_time": "2019-11-15T04:41:19.409000Z"
    }
   },
   "outputs": [],
   "source": [
    "class Apriori(object):\n",
    "    def __init__(self, minSupp, minConf):\n",
    "        \"\"\" Parameters setting\n",
    "        \"\"\"\n",
    "        self.minSupp = minSupp  # min support (used for mining frequent sets)\n",
    "        self.minConf = minConf  # min confidence (used for mining association rules)\n",
    "\n",
    "    def fit(self, filePath):\n",
    "        \"\"\" Run the apriori algorithm, return the frequent *-term sets. \n",
    "        \"\"\"\n",
    "        # Initialize some variables to hold the tmp result\n",
    "        transListSet  = self.getTransListSet(filePath)   # get transactions (list that contain sets)\n",
    "        itemSet       = self.getOneItemSet(transListSet) # get 1-item set\n",
    "        itemCountDict = defaultdict(int)         # key=candiate k-item(k=1/2/...), value=count\n",
    "        freqSet       = dict()                   # a dict store all frequent *-items set\n",
    "        \n",
    "        self.transLength = len(transListSet)     # number of transactions\n",
    "        self.itemSet     = itemSet\n",
    "        \n",
    "        # Get the frequent 1-term set\n",
    "        freqOneTermSet = self.getItemsWithMinSupp(transListSet, itemSet, \n",
    "                                             itemCountDict, self.minSupp)\n",
    "\n",
    "        # Main loop\n",
    "        k = 1\n",
    "        currFreqTermSet = freqOneTermSet\n",
    "        while currFreqTermSet != set():\n",
    "            freqSet[k] = currFreqTermSet  # save the result\n",
    "            k += 1\n",
    "            currCandiItemSet = self.getJoinedItemSet(currFreqTermSet, k) # get new candiate k-terms set\n",
    "            currFreqTermSet  = self.getItemsWithMinSupp(transListSet, currCandiItemSet, \n",
    "                                                   itemCountDict, self.minSupp) # frequent k-terms set\n",
    "            \n",
    "            \n",
    "        #\n",
    "        self.itemCountDict = itemCountDict # 所有候选项以及出现的次数(不仅仅是频繁项),用来计算置信度啊\n",
    "        self.freqSet       = freqSet       # Only frequent items(a dict: freqSet[1] indicate frequent 1-term set )\n",
    "        return itemCountDict, freqSet\n",
    "            \n",
    "            \n",
    "    def getSpecRules(self, rhs):\n",
    "        \"\"\" Specify a right item, construct rules for it\n",
    "        \"\"\"\n",
    "        if rhs not in self.itemSet:\n",
    "            print('Please input a term contain in the term-set !')\n",
    "            return None\n",
    "        \n",
    "        rules = dict()\n",
    "        for key, value in self.freqSet.items():\n",
    "            for item in value:\n",
    "                if rhs.issubset(item) and len(item) > 1:\n",
    "                    item_supp = self.getSupport(item)\n",
    "                    item = item.difference(rhs)\n",
    "                    conf = item_supp / self.getSupport(item)\n",
    "                    if conf >= self.minConf:\n",
    "                        rules[item] = conf\n",
    "        return rules\n",
    "        \n",
    "    \n",
    "    def getSupport(self, item):\n",
    "        \"\"\" Get the support of item \"\"\"\n",
    "        return self.itemCountDict[item] / self.transLength\n",
    "        \n",
    "        \n",
    "    def getJoinedItemSet(self, termSet, k):\n",
    "        \"\"\" Generate new k-terms candiate itemset\"\"\"\n",
    "        return set([term1.union(term2) for term1 in termSet for term2 in termSet \n",
    "                    if len(term1.union(term2))==k])\n",
    "    \n",
    "        \n",
    "    def getOneItemSet(self, transListSet):\n",
    "        \"\"\" Get unique 1-item set in `set` format \n",
    "        \"\"\"\n",
    "        itemSet = set()\n",
    "        for line in transListSet:\n",
    "            for item in line:\n",
    "                itemSet.add(frozenset([item]))\n",
    "        return itemSet\n",
    "        \n",
    "    \n",
    "    def getTransListSet(self, filePath):\n",
    "        \"\"\" Get transactions in list format \n",
    "        \"\"\"\n",
    "        transListSet = []\n",
    "        with open(filePath, 'r') as file:\n",
    "            reader = csv.reader(file, delimiter=',')\n",
    "            for line in reader:\n",
    "                transListSet.append(set(line))                \n",
    "        return transListSet\n",
    "                \n",
    "    \n",
    "    def getItemsWithMinSupp(self, transListSet, itemSet, freqSet, minSupp):\n",
    "        \"\"\" Get frequent item set using min support\n",
    "        \"\"\"\n",
    "        itemSet_  = set()\n",
    "        localSet_ = defaultdict(int)\n",
    "        for item in itemSet:\n",
    "            freqSet[item]   += sum([1 for trans in transListSet if item.issubset(trans)])\n",
    "            localSet_[item] += sum([1 for trans in transListSet if item.issubset(trans)])\n",
    "        \n",
    "        # Only conserve frequent item-set \n",
    "        n = len(transListSet)\n",
    "        for item, cnt in localSet_.items():\n",
    "            itemSet_.add(item) if float(cnt)/n >= minSupp else None\n",
    "        \n",
    "        return itemSet_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=title2>\n",
    "    <b><font size='3'>Calculate Apriori (Association)</font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T04:49:29.731000Z",
     "start_time": "2019-11-15T04:49:29.702000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: \n",
      " - filePath: ./data/transaction_hci.csv \n",
      " - mininum support: 0.15 \n",
      " - mininum confidence: 0.5 \n",
      " - rhs: frozenset({'Backpack'})\n",
      "\n",
      "frequent 1-term set:\n",
      "--------------------\n",
      "['FitBit']\n",
      "['TP-Link']\n",
      "['Nivea']\n",
      "['Mouse']\n",
      "['GoPro']\n",
      "['Yonex']\n",
      "['Music-Sampler']\n",
      "['Guitar']\n",
      "['Xiaomi']\n",
      "['Backpack']\n",
      "\n",
      "frequent 2-term set:\n",
      "--------------------\n",
      "['TP-Link', 'Mouse']\n",
      "['Backpack', 'Guitar']\n",
      "['Backpack', 'Xiaomi']\n",
      "['GoPro', 'FitBit']\n",
      "['Mouse', 'Backpack']\n",
      "\n",
      "--------------------\n",
      "rules refer to ['Backpack']\n",
      "['Guitar'] -> ['Backpack']: 0.5384615384615384\n",
      "['Xiaomi'] -> ['Backpack']: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Get two important parameters\n",
    "filePath = './data/transaction_hci.csv'\n",
    "minSupp  = 0.15\n",
    "minConf  = 0.5\n",
    "rhs      = frozenset(['Backpack'])\n",
    "print(\"\"\"Parameters: \\n - filePath: {} \\n - mininum support: {} \\n - mininum confidence: {} \\n - rhs: {}\\n\"\"\".\\\n",
    "      format(filePath,minSupp,minConf, rhs))\n",
    "\n",
    "# Run and print\n",
    "objApriori = Apriori(minSupp, minConf)\n",
    "itemCountDict, freqSet = objApriori.fit(filePath)\n",
    "for key, value in freqSet.items():\n",
    "    print('frequent {}-term set:'.format(key))\n",
    "    print('-'*20)\n",
    "    for itemset in value:\n",
    "        print(list(itemset))\n",
    "    print()\n",
    "\n",
    "# Return rules with regard of `rhs`\n",
    "rules = objApriori.getSpecRules(rhs)\n",
    "print('-'*20)\n",
    "print('rules refer to {}'.format(list(rhs)))\n",
    "for key, value in rules.items():\n",
    "    print('{} -> {}: {}'.format(list(key), list(rhs), value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=title1>\n",
    "    <b><font size='4'>Collaborative Filtering</font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=title2>\n",
    "    <b><font size='3'>aryankashyap0</font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=title2>\n",
    "    <b><font size='3'>Define Dataset</font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T04:53:12.862000Z",
     "start_time": "2019-11-15T04:53:12.856000Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset={'Alice': {'Love At Last': 5, \n",
    "                   'Romance Forever': 5,\n",
    "                   'Cute puppies of love': 0, \n",
    "                   'Nonstop car chases': 0, \n",
    "                   'Swords vs karate': 0},\n",
    "         \n",
    "         'Bob': {'Love At Last': 5,\n",
    "                 'Romance Forever': 0,\n",
    "                 'Cute puppies of love': 4,\n",
    "                 'Nonstop car chases': 0,\n",
    "                 'Swords vs karate': 0},\n",
    "         \n",
    "         'Carol': {'Love At Last': 0, \n",
    "                   'Romance Forever': 0,\n",
    "                   'Cute puppies of love': 0,\n",
    "                   'Nonstop car chases': 5,\n",
    "                   'Swords vs karate': 5},\n",
    "         \n",
    "         'Dave': {'Love At Last': 0, \n",
    "                  'Romance Forever': 0,\n",
    "                  'Cute puppies of love': 0,\n",
    "                  'Nonstop car chases': 4,\n",
    "                  'Swords vs karate': 0}\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T04:54:43.081000Z",
     "start_time": "2019-11-15T04:54:43.073000Z"
    }
   },
   "source": [
    "<div class=title2>\n",
    "    <b><font size='3'>Define Similarity Score</font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T04:57:02.992000Z",
     "start_time": "2019-11-15T04:57:02.977000Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def similarity_score(person1,person2):\n",
    "\n",
    "    # this Returns the ration euclidean distancen score of person 1 and 2\n",
    "\n",
    "    # To get both rated items by person 1 and 2\n",
    "    both_viewed = {}\n",
    "\n",
    "    for item in dataset[person1]:\n",
    "        if item in dataset[person2]:\n",
    "            both_viewed[item] = 1\n",
    "        \n",
    "        # The Conditions to check if they both have common rating items\n",
    "        if len(both_viewed) == 0:\n",
    "            return 0\n",
    "\n",
    "        # Finding Euclidean distance\n",
    "        sum_of_eclidean_distance = []\n",
    "\n",
    "        for item in dataset[person1]:\n",
    "            if item in dataset[person2]:\n",
    "                sum_of_eclidean_distance.append(pow(dataset[person1][item] - dataset[person2][item], 2))\n",
    "        sum_of_eclidean_distance = sum(sum_of_eclidean_distance)\n",
    "        \n",
    "        return 1/(1+sqrt(sum_of_eclidean_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T04:57:05.432000Z",
     "start_time": "2019-11-15T04:57:05.419000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13507810593582123\n"
     ]
    }
   ],
   "source": [
    "print(similarity_score('Alice','Bob'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=title2>\n",
    "    <b><font size='3'>Define Person Correlation</font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T04:58:01.060000Z",
     "start_time": "2019-11-15T04:58:01.032000Z"
    }
   },
   "outputs": [],
   "source": [
    "def person_correlation(person1, person2):\n",
    "\n",
    "   # To get both rated items\n",
    "    both_rated = {}\n",
    "    for item in dataset[person1]:\n",
    "        if item in dataset[person2]:\n",
    "            both_rated[item] = 1\n",
    "\n",
    "    number_of_ratings = len(both_rated)\n",
    "\n",
    "    # Checking for ratings in common\n",
    "    if number_of_ratings == 0:\n",
    "        return 0\n",
    "\n",
    "    # Add up all the preferences of each user\n",
    "    person1_preferences_sum = sum([dataset[person1][item] for item in both_rated])\n",
    "    person2_preferences_sum = sum([dataset[person2][item] for item in both_rated])\n",
    "\n",
    "    # Sum up the squares of preferences of each user\n",
    "    person1_square_preferences_sum = sum([pow(dataset[person1][item],2) for item in both_rated])\n",
    "    person2_square_preferences_sum = sum([pow(dataset[person2][item],2) for item in both_rated])\n",
    "\n",
    "    # Sum up the product value of both preferences for each item\n",
    "    product_sum_of_both_users = sum([dataset[person1][item] * dataset[person2][item] for item in both_rated])\n",
    "\n",
    "    # Calculate the pearson score\n",
    "    numerator_value = product_sum_of_both_users - (person1_preferences_sum*person2_preferences_sum/number_of_ratings)\n",
    "    denominator_value = sqrt((person1_square_preferences_sum - pow(person1_preferences_sum,2)/number_of_ratings) * (person2_square_preferences_sum -pow(person2_preferences_sum,2)/number_of_ratings))\n",
    "\n",
    "    if denominator_value == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        r = numerator_value / denominator_value\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T04:58:16.294000Z",
     "start_time": "2019-11-15T04:58:16.281000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2566324512873683\n"
     ]
    }
   ],
   "source": [
    "print(person_correlation('Alice','Bob'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=title2>\n",
    "    <b><font size='3'>Define Most Similar Users</font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T04:59:05.537000Z",
     "start_time": "2019-11-15T04:59:05.524000Z"
    }
   },
   "outputs": [],
   "source": [
    "def most_similar_users(person, number_of_users):\n",
    "\n",
    "    # returns the number_of_users (similar persons) for a given specific person\n",
    "    scores = [(person_correlation(person, other_person), other_person) for other_person in dataset if other_person != person]\n",
    "\n",
    "    # Sort the similar persons so the highest scores person will appear at the first\n",
    "    scores.sort()\n",
    "    scores.reverse()\n",
    "    return scores[0:number_of_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T04:59:26.005000Z",
     "start_time": "2019-11-15T04:59:25.996000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.2566324512873683, 'Bob'), (-0.4082482904638631, 'Dave'), (-0.6666666666666666, 'Carol')]\n"
     ]
    }
   ],
   "source": [
    "print(most_similar_users('Alice',3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=title2>\n",
    "    <b><font size='3'>Define User Recommendations</font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T05:00:42.765000Z",
     "start_time": "2019-11-15T05:00:42.752000Z"
    }
   },
   "outputs": [],
   "source": [
    "def user_recommendations(person):\n",
    "\n",
    "    # Gets recommendations for a person by using a weighted average of every other user's rankings\n",
    "    totals = {}\n",
    "    simSums = {}\n",
    "    rankings_list =[]\n",
    "    for other in dataset:\n",
    "        # don't compare me to myself\n",
    "        if other == person:\n",
    "            continue\n",
    "        sim = person_correlation(person,other)\n",
    "        #print \">>>>>>>\",sim\n",
    "\n",
    "        # ignore scores of zero or lower\n",
    "        if sim <=0: \n",
    "            continue\n",
    "        for item in dataset[other]:\n",
    "\n",
    "            # only score movies i haven't seen yet\n",
    "            if item not in dataset[person] or dataset[person][item] == 0:\n",
    "\n",
    "            # Similrity * score\n",
    "                totals.setdefault(item,0)\n",
    "                totals[item] += dataset[other][item]* sim\n",
    "                # sum of similarities\n",
    "                simSums.setdefault(item,0)\n",
    "                simSums[item]+= sim\n",
    "\n",
    "        # Create the normalized list\n",
    "\n",
    "    rankings = [(total/simSums[item],item) for item,total in totals.items()]\n",
    "    rankings.sort()\n",
    "    rankings.reverse()\n",
    "    # returns the recommended items\n",
    "    recommendataions_list = [recommend_item for score, recommend_item in rankings]\n",
    "    return recommendataions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T05:00:53.109000Z",
     "start_time": "2019-11-15T05:00:53.096000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cute puppies of love', 'Swords vs karate', 'Nonstop car chases']\n"
     ]
    }
   ],
   "source": [
    "print(user_recommendations('Alice'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T06:45:51.588000Z",
     "start_time": "2019-11-15T06:45:51.584000Z"
    }
   },
   "source": [
    "<div class=title2>\n",
    "    <b><font size='3'>revantkumar</font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T06:47:35.961000Z",
     "start_time": "2019-11-15T06:47:35.954000Z"
    }
   },
   "source": [
    "<div class=title2>\n",
    "    <b><font size='3'>User Based</font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T07:04:38.304000Z",
     "start_time": "2019-11-15T07:04:38.224000Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ratings.csv,toBeRated.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-8a42d384d6a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mfw_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m \u001b[0mrecommend_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadingFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ratings.csv,toBeRated.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;31m# recommend_data = readingFile(sys.argv[1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;31m# recommend_data = readingFile(['ratings.csv', 'toBeRated.csv'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-8a42d384d6a8>\u001b[0m in \u001b[0;36mreadingFile\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mreadingFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ratings.csv,toBeRated.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.spatial\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import math\n",
    "#from sklearn.utils.extmath import np.dot\n",
    "\n",
    "users = 6040\n",
    "items = 3952\n",
    "\n",
    "def readingFile(filename):\n",
    "\tf = open(filename,\"r\")\n",
    "\tdata = []\n",
    "\tfor row in f:\n",
    "\t\tr = row.split(',')\n",
    "\t\te = [int(r[0]), int(r[1]), int(r[2])]\n",
    "\t\tdata.append(e)\n",
    "\treturn data\n",
    "\n",
    "def similarity_user(data):\n",
    "\tprint (\"Hello User\")\n",
    "\t#f_i_d = open(\"sim_user_based.txt\",\"w\")\n",
    "\tuser_similarity_cosine = np.zeros((users,users))\n",
    "\tuser_similarity_jaccard = np.zeros((users,users))\n",
    "\tuser_similarity_pearson = np.zeros((users,users))\n",
    "\tfor user1 in range(users):\n",
    "\t\tprint (user1)\n",
    "\t\tfor user2 in range(users):\n",
    "\t\t\tif np.count_nonzero(data[user1]) and np.count_nonzero(data[user2]):\n",
    "\t\t\t\tuser_similarity_cosine[user1][user2] = 1-scipy.spatial.distance.cosine(data[user1],data[user2])\n",
    "\t\t\t\tuser_similarity_jaccard[user1][user2] = 1-scipy.spatial.distance.jaccard(data[user1],data[user2])\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tif not math.isnan(scipy.stats.pearsonr(data[user1],data[user2])[0]):\n",
    "\t\t\t\t\t\tuser_similarity_pearson[user1][user2] = scipy.stats.pearsonr(data[user1],data[user2])[0]\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tuser_similarity_pearson[user1][user2] = 0\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tuser_similarity_pearson[user1][user2] = 0\n",
    "\n",
    "\t\t\t#f_i_d.write(str(user1) + \",\" + str(user2) + \",\" + str(user_similarity_cosine[user1][user2]) + \",\" + str(user_similarity_jaccard[user1][user2]) + \",\" + str(user_similarity_pearson[user1][user2]) + \"\\n\")\n",
    "\t#f_i_d.close()\n",
    "\treturn user_similarity_cosine, user_similarity_jaccard, user_similarity_pearson\n",
    "\n",
    "def crossValidation(data):\n",
    "\tk_fold = KFold(n_splits=10)\n",
    "\n",
    "\tMat = np.zeros((users,items))\n",
    "\tfor e in data:\n",
    "\t\tMat[e[0]-1][e[1]-1] = e[2]\n",
    "\n",
    "\tsim_user_cosine, sim_user_jaccard, sim_user_pearson = similarity_user(Mat)\n",
    "\t#sim_user_cosine, sim_user_jaccard, sim_user_pearson = np.random.rand(users,users), np.random.rand(users,users), np.random.rand(users,users)\n",
    "\n",
    "\t'''sim_user_cosine = np.zeros((users,users))\n",
    "\tsim_user_jaccard = np.zeros((users,users))\n",
    "\tsim_user_pearson = np.zeros((users,users))\n",
    "\n",
    "\tf_sim = open(\"sim_user_based.txt\", \"r\")\n",
    "\tfor row in f_sim:\n",
    "\t\tr = row.strip().split(',')\n",
    "\t\tsim_user_cosine[int(r[0])][int(r[1])] = float(r[2])\n",
    "\t\tsim_user_jaccard[int(r[0])][int(r[1])] = float(r[3])\n",
    "\t\tsim_user_pearson[int(r[0])][int(r[1])] = float(r[4])\n",
    "\tf_sim.close()'''\n",
    "\n",
    "\trmse_cosine = []\n",
    "\trmse_jaccard = []\n",
    "\trmse_pearson = []\n",
    "\n",
    "\tfor train_indices, test_indices in k_fold:\n",
    "\t\ttrain = [data[i] for i in train_indices]\n",
    "\t\ttest = [data[i] for i in test_indices]\n",
    "\n",
    "\t\tM = np.zeros((users,items))\n",
    "\n",
    "\t\tfor e in train:\n",
    "\t\t\tM[e[0]-1][e[1]-1] = e[2]\n",
    "\n",
    "\t\ttrue_rate = []\n",
    "\t\tpred_rate_cosine = []\n",
    "\t\tpred_rate_jaccard = []\n",
    "\t\tpred_rate_pearson = []\n",
    "\n",
    "\t\tfor e in test:\n",
    "\t\t\tuser = e[0]\n",
    "\t\t\titem = e[1]\n",
    "\t\t\ttrue_rate.append(e[2])\n",
    "\n",
    "\t\t\tpred_cosine = 3.0\n",
    "\t\t\tpred_jaccard = 3.0\n",
    "\t\t\tpred_pearson = 3.0\n",
    "\n",
    "\t\t\t#user-based\n",
    "\t\t\tif np.count_nonzero(M[user-1]):\n",
    "\t\t\t\tsim_cosine = sim_user_cosine[user-1]\n",
    "\t\t\t\tsim_jaccard = sim_user_jaccard[user-1]\n",
    "\t\t\t\tsim_pearson = sim_user_pearson[user-1]\n",
    "\t\t\t\tind = (M[:,item-1] > 0)\n",
    "\t\t\t\t#ind[user-1] = False\n",
    "\t\t\t\tnormal_cosine = np.sum(np.absolute(sim_cosine[ind]))\n",
    "\t\t\t\tnormal_jaccard = np.sum(np.absolute(sim_jaccard[ind]))\n",
    "\t\t\t\tnormal_pearson = np.sum(np.absolute(sim_pearson[ind]))\n",
    "\t\t\t\tif normal_cosine > 0:\n",
    "\t\t\t\t\tpred_cosine = np.dot(sim_cosine,M[:,item-1])/normal_cosine\n",
    "\n",
    "\t\t\t\tif normal_jaccard > 0:\n",
    "\t\t\t\t\tpred_jaccard = np.dot(sim_jaccard,M[:,item-1])/normal_jaccard\n",
    "\n",
    "\t\t\t\tif normal_pearson > 0:\n",
    "\t\t\t\t\tpred_pearson = np.dot(sim_pearson,M[:,item-1])/normal_pearson\n",
    "\n",
    "\t\t\tif pred_cosine < 0:\n",
    "\t\t\t\tpred_cosine = 0\n",
    "\n",
    "\t\t\tif pred_cosine > 5:\n",
    "\t\t\t\tpred_cosine = 5\n",
    "\n",
    "\t\t\tif pred_jaccard < 0:\n",
    "\t\t\t\tpred_jaccard = 0\n",
    "\n",
    "\t\t\tif pred_jaccard > 5:\n",
    "\t\t\t\tpred_jaccard = 5\n",
    "\n",
    "\t\t\tif pred_pearson < 0:\n",
    "\t\t\t\tpred_pearson = 0\n",
    "\n",
    "\t\t\tif pred_pearson > 5:\n",
    "\t\t\t\tpred_pearson = 5\n",
    "\n",
    "\t\t\tprint (str(user) + \"\\t\" + str(item) + \"\\t\" + str(e[2]) + \"\\t\" + str(pred_cosine) + \"\\t\" + str(pred_jaccard) + \"\\t\" + str(pred_pearson))\n",
    "\t\t\tpred_rate_cosine.append(pred_cosine)\n",
    "\t\t\tpred_rate_jaccard.append(pred_jaccard)\n",
    "\t\t\tpred_rate_pearson.append(pred_pearson)\n",
    "\n",
    "\t\trmse_cosine.append(sqrt(mean_squared_error(true_rate, pred_rate_cosine)))\n",
    "\t\trmse_jaccard.append(sqrt(mean_squared_error(true_rate, pred_rate_jaccard)))\n",
    "\t\trmse_pearson.append(sqrt(mean_squared_error(true_rate, pred_rate_pearson)))\n",
    "\n",
    "\t\tprint (str(sqrt(mean_squared_error(true_rate, pred_rate_cosine))) + \"\\t\" + str(sqrt(mean_squared_error(true_rate, pred_rate_jaccard))) + \"\\t\" + str(sqrt(mean_squared_error(true_rate, pred_rate_pearson))))\n",
    "\t\t#raw_input()\n",
    "\n",
    "\t#print sum(rms) / float(len(rms))\n",
    "\trmse_cosine = sum(rmse_cosine) / float(len(rmse_cosine))\n",
    "\trmse_pearson = sum(rmse_pearson) / float(len(rmse_pearson))\n",
    "\trmse_jaccard = sum(rmse_jaccard) / float(len(rmse_jaccard))\n",
    "\n",
    "\tprint (str(rmse_cosine) + \"\\t\" + str(rmse_jaccard) + \"\\t\" + str(rmse_pearson))\n",
    "\n",
    "\tf_rmse = open(\"rmse_user.txt\",\"w\")\n",
    "\tf_rmse.write(str(rmse_cosine) + \"\\t\" + str(rmse_jaccard) + \"\\t\" + str(rmse_pearson) + \"\\n\")\n",
    "\n",
    "\trmse = [rmse_cosine, rmse_jaccard, rmse_pearson]\n",
    "\treq_sim = rmse.index(min(rmse))\n",
    "\n",
    "\tprint (req_sim)\n",
    "\tf_rmse.write(str(req_sim))\n",
    "\tf_rmse.close()\n",
    "\n",
    "\tif req_sim == 0:\n",
    "\t\tsim_mat_user = sim_user_cosine\n",
    "\n",
    "\tif req_sim == 1:\n",
    "\t\tsim_mat_user = sim_user_jaccard\n",
    "\n",
    "\tif req_sim == 2:\n",
    "\t\tsim_mat_user = sim_user_pearson\n",
    "\n",
    "\t#predictRating(Mat, sim_mat_user)\n",
    "\treturn Mat, sim_mat_user\n",
    "\n",
    "\n",
    "def predictRating(recommend_data):\n",
    "\n",
    "\tM, sim_user = crossValidation(recommend_data)\n",
    "\n",
    "\t#f = open(\"toBeRated.csv\",\"r\")\n",
    "\tf = open(sys.argv[2],\"r\")\n",
    "\ttoBeRated = {\"user\":[], \"item\":[]}\n",
    "\tfor row in f:\n",
    "\t\tr = row.split(',')\t\n",
    "\t\ttoBeRated[\"item\"].append(int(r[1]))\n",
    "\t\ttoBeRated[\"user\"].append(int(r[0]))\n",
    "\n",
    "\tf.close()\n",
    "\n",
    "\tpred_rate = []\n",
    "\n",
    "\t#fw = open('result1.csv','w')\n",
    "\tfw_w = open('result1.csv','w')\n",
    "\n",
    "\tl = len(toBeRated[\"user\"])\n",
    "\tfor e in range(l):\n",
    "\t\tuser = toBeRated[\"user\"][e]\n",
    "\t\titem = toBeRated[\"item\"][e]\n",
    "\n",
    "\t\tpred = 3.0\n",
    "\n",
    "\t\t#user-based\n",
    "\t\tif np.count_nonzero(M[user-1]):\n",
    "\t\t\tsim = sim_user[user-1]\n",
    "\t\t\tind = (M[:,item-1] > 0)\n",
    "\t\t\t#ind[user-1] = False\n",
    "\t\t\tnormal = np.sum(np.absolute(sim[ind]))\n",
    "\t\t\tif normal > 0:\n",
    "\t\t\t\tpred = np.dot(sim,M[:,item-1])/normal\n",
    "\n",
    "\t\tif pred < 0:\n",
    "\t\t\tpred = 0\n",
    "\n",
    "\t\tif pred > 5:\n",
    "\t\t\tpred = 5\n",
    "\n",
    "\t\tpred_rate.append(pred)\n",
    "\t\tprint (str(user) + \",\" + str(item) + \",\" + str(pred))\n",
    "\t\t#fw.write(str(user) + \",\" + str(item) + \",\" + str(pred) + \"\\n\")\n",
    "\t\tfw_w.write(str(pred) + \"\\n\")\n",
    "\n",
    "\t#fw.close()\n",
    "\tfw_w.close()\n",
    "\n",
    "recommend_data = readingFile(\"ratings.csv\")\n",
    "# recommend_data = readingFile(sys.argv[1])\n",
    "# recommend_data = readingFile(['ratings.csv', 'toBeRated.csv'])\n",
    "#crossValidation(recommend_data)\n",
    "predictRating(recommend_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=title2>\n",
    "    <b><font size='3'>Item Based</font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T06:58:16.469000Z",
     "start_time": "2019-11-15T06:58:11.841000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-dfffb9c243dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;31m# recommend_data = readingFile(sys.argv[1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;31m#crossValidation(recommend_data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m \u001b[0mpredictRating\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecommend_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-41-dfffb9c243dd>\u001b[0m in \u001b[0;36mpredictRating\u001b[1;34m(recommend_data)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredictRating\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecommend_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim_item\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrossValidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecommend_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;31m#f = open(\"toBeRated.csv\",\"r\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-dfffb9c243dd>\u001b[0m in \u001b[0;36mcrossValidation\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[0mMat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0msim_item_cosine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim_item_jaccard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim_item_pearson\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimilarity_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[1;31m#sim_item_cosine, sim_item_jaccard, sim_item_pearson = np.random.rand(items,items), np.random.rand(items,items), np.random.rand(items,items)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-dfffb9c243dd>\u001b[0m in \u001b[0;36msimilarity_item\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mitem2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitem1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitem2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                                 \u001b[0mitem_similarity_cosine\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitem1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitem2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                                 \u001b[0mitem_similarity_jaccard\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjaccard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitem1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitem2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py\u001b[0m in \u001b[0;36mcosine\u001b[1;34m(u, v, w)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;31m# cosine distance is also referred to as 'uncentered correlation',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;31m#   or 'reflective correlation'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcorrelation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcentered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py\u001b[0m in \u001b[0;36mcorrelation\u001b[1;34m(u, v, w, centered)\u001b[0m\n\u001b[0;32m    707\u001b[0m     \"\"\"\n\u001b[0;32m    708\u001b[0m     \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py\u001b[0m in \u001b[0;36m_validate_vector\u001b[1;34m(u, dtype)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;31m# XXX Is order='c' really necessary?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m     \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m     \u001b[1;31m# Ensure values such as u=1 and u=[1] still return 1-D arrays.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.spatial\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import math\n",
    "#from sklearn.utils.extmath import np.dot\n",
    "\n",
    "users = 6040\n",
    "items = 3952\n",
    "\n",
    "def readingFile(filename):\n",
    "\tf = open(filename,\"r\")\n",
    "\tdata = []\n",
    "\tfor row in f:\n",
    "\t\tr = row.split(',')\n",
    "\t\te = [int(r[0]), int(r[1]), int(r[2])]\n",
    "\t\tdata.append(e)\n",
    "\treturn data\n",
    "\n",
    "def similarity_item(data):\n",
    "\tprint(\"Hello\")\n",
    "\t#f_i_d = open(\"sim_item_based.txt\",\"w\")\n",
    "\titem_similarity_cosine = np.zeros((items,items))\n",
    "\titem_similarity_jaccard = np.zeros((items,items))\n",
    "\titem_similarity_pearson = np.zeros((items,items))\n",
    "\tfor item1 in range(items):\n",
    "\t\tprint(item1)\n",
    "\t\tfor item2 in range(items):\n",
    "\t\t\tif np.count_nonzero(data[:,item1]) and np.count_nonzero(data[:,item2]):\n",
    "\t\t\t\titem_similarity_cosine[item1][item2] = 1-scipy.spatial.distance.cosine(data[:,item1],data[:,item2])\n",
    "\t\t\t\titem_similarity_jaccard[item1][item2] = 1-scipy.spatial.distance.jaccard(data[:,item1],data[:,item2])\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tif not math.isnan(scipy.stats.pearsonr(data[:,item1],data[:,item2])[0]):\n",
    "\t\t\t\t\t\titem_similarity_pearson[item1][item2] = scipy.stats.pearsonr(data[:,item1],data[:,item2])[0]\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\titem_similarity_pearson[item1][item2] = 0\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\titem_similarity_pearson[item1][item2] = 0\n",
    "\n",
    "\t\t\t#f_i_d.write(str(item1) + \",\" + str(item2) + \",\" + str(item_similarity_cosine[item1][item2]) + \",\" + str(item_similarity_jaccard[item1][item2]) + \",\" + str(item_similarity_pearson[item1][item2]) + \"\\n\")\n",
    "\t#f_i_d.close()\n",
    "\treturn item_similarity_cosine, item_similarity_jaccard, item_similarity_pearson\n",
    "\n",
    "def crossValidation(data):\n",
    "\tk_fold = KFold(n_splits=10)\n",
    "\n",
    "\tMat = np.zeros((users,items))\n",
    "\tfor e in data:\n",
    "\t\tMat[e[0]-1][e[1]-1] = e[2]\n",
    "\n",
    "\tsim_item_cosine, sim_item_jaccard, sim_item_pearson = similarity_item(Mat)\n",
    "\t#sim_item_cosine, sim_item_jaccard, sim_item_pearson = np.random.rand(items,items), np.random.rand(items,items), np.random.rand(items,items) \n",
    "\n",
    "\t'''sim_item_cosine = np.zeros((items,items))\n",
    "\tsim_item_jaccard = np.zeros((items,items))\n",
    "\tsim_item_pearson = np.zeros((items,items))\n",
    "\n",
    "\tf_sim_i = open(\"sim_item_based.txt\", \"r\")\n",
    "\tfor row in f_sim_i:\n",
    "\t\tr = row.strip().split(',')\n",
    "\t\tsim_item_cosine[int(r[0])][int(r[1])] = float(r[2])\n",
    "\t\tsim_item_jaccard[int(r[0])][int(r[1])] = float(r[3])\n",
    "\t\tsim_item_pearson[int(r[0])][int(r[1])] = float(r[4])\n",
    "\tf_sim_i.close()'''\n",
    "\n",
    "\trmse_cosine = []\n",
    "\trmse_jaccard = []\n",
    "\trmse_pearson = []\n",
    "\n",
    "\tfor train_indices, test_indices in k_fold:\n",
    "\t\ttrain = [data[i] for i in train_indices]\n",
    "\t\ttest = [data[i] for i in test_indices]\n",
    "\n",
    "\t\tM = np.zeros((users,items))\n",
    "\n",
    "\t\tfor e in train:\n",
    "\t\t\tM[e[0]-1][e[1]-1] = e[2]\n",
    "\n",
    "\t\ttrue_rate = []\n",
    "\t\tpred_rate_cosine = []\n",
    "\t\tpred_rate_jaccard = []\n",
    "\t\tpred_rate_pearson = []\n",
    "\n",
    "\t\tfor e in test:\n",
    "\t\t\tuser = e[0]\n",
    "\t\t\titem = e[1]\n",
    "\t\t\ttrue_rate.append(e[2])\n",
    "\n",
    "\t\t\tpred_cosine = 3.0\n",
    "\t\t\tpred_jaccard = 3.0\n",
    "\t\t\tpred_pearson = 3.0\n",
    "\n",
    "\t\t\t#item-based\n",
    "\t\t\tif np.count_nonzero(M[:,item-1]):\n",
    "\t\t\t\tsim_cosine = sim_item_cosine[item-1]\n",
    "\t\t\t\tsim_jaccard = sim_item_jaccard[item-1]\n",
    "\t\t\t\tsim_pearson = sim_item_pearson[item-1]\n",
    "\t\t\t\tind = (M[user-1] > 0)\n",
    "\t\t\t\t#ind[item-1] = False\n",
    "\t\t\t\tnormal_cosine = np.sum(np.absolute(sim_cosine[ind]))\n",
    "\t\t\t\tnormal_jaccard = np.sum(np.absolute(sim_jaccard[ind]))\n",
    "\t\t\t\tnormal_pearson = np.sum(np.absolute(sim_pearson[ind]))\n",
    "\t\t\t\tif normal_cosine > 0:\n",
    "\t\t\t\t\tpred_cosine = np.dot(sim_cosine,M[user-1])/normal_cosine\n",
    "\n",
    "\t\t\t\tif normal_jaccard > 0:\n",
    "\t\t\t\t\tpred_jaccard = np.dot(sim_jaccard,M[user-1])/normal_jaccard\n",
    "\n",
    "\t\t\t\tif normal_pearson > 0:\n",
    "\t\t\t\t\tpred_pearson = np.dot(sim_pearson,M[user-1])/normal_pearson\n",
    "\n",
    "\t\t\tif pred_cosine < 0:\n",
    "\t\t\t\tpred_cosine = 0\n",
    "\n",
    "\t\t\tif pred_cosine > 5:\n",
    "\t\t\t\tpred_cosine = 5\n",
    "\n",
    "\t\t\tif pred_jaccard < 0:\n",
    "\t\t\t\tpred_jaccard = 0\n",
    "\n",
    "\t\t\tif pred_jaccard > 5:\n",
    "\t\t\t\tpred_jaccard = 5\n",
    "\n",
    "\t\t\tif pred_pearson < 0:\n",
    "\t\t\t\tpred_pearson = 0\n",
    "\n",
    "\t\t\tif pred_pearson > 5:\n",
    "\t\t\t\tpred_pearson = 5\n",
    "\n",
    "\t\t\tprint(str(user) + \"\\t\" + str(item) + \"\\t\" + str(e[2]) + \"\\t\" + str(pred_cosine) + \"\\t\" + str(pred_jaccard) + \"\\t\" + str(pred_pearson))\n",
    "\t\t\tpred_rate_cosine.append(pred_cosine)\n",
    "\t\t\tpred_rate_jaccard.append(pred_jaccard)\n",
    "\t\t\tpred_rate_pearson.append(pred_pearson)\n",
    "\n",
    "\t\trmse_cosine.append(sqrt(mean_squared_error(true_rate, pred_rate_cosine)))\n",
    "\t\trmse_jaccard.append(sqrt(mean_squared_error(true_rate, pred_rate_jaccard)))\n",
    "\t\trmse_pearson.append(sqrt(mean_squared_error(true_rate, pred_rate_pearson)))\n",
    "\n",
    "\t\tprint(str(sqrt(mean_squared_error(true_rate, pred_rate_cosine))) + \"\\t\" + str(sqrt(mean_squared_error(true_rate, pred_rate_jaccard))) + \"\\t\" + str(sqrt(mean_squared_error(true_rate, pred_rate_pearson))))\n",
    "\t\t#raw_input()\n",
    "\n",
    "\t#print sum(rms) / float(len(rms))\n",
    "\trmse_cosine = sum(rmse_cosine) / float(len(rmse_cosine))\n",
    "\trmse_pearson = sum(rmse_pearson) / float(len(rmse_pearson))\n",
    "\trmse_jaccard = sum(rmse_jaccard) / float(len(rmse_jaccard))\n",
    "\n",
    "\tprint(str(rmse_cosine) + \"\\t\" + str(rmse_jaccard) + \"\\t\" + str(rmse_pearson))\n",
    "\n",
    "\tf_rmse = open(\"rmse_item.txt\",\"w\")\n",
    "\tf_rmse.write(str(rmse_cosine) + \"\\t\" + str(rmse_jaccard) + \"\\t\" + str(rmse_pearson) + \"\\n\")\n",
    "\n",
    "\trmse = [rmse_cosine, rmse_jaccard, rmse_pearson]\n",
    "\treq_sim = rmse.index(min(rmse))\n",
    "\n",
    "\tprint(req_sim)\n",
    "\tf_rmse.write(str(req_sim))\n",
    "\tf_rmse.close()\n",
    "\n",
    "\tif req_sim == 0:\n",
    "\t\tsim_mat_item = sim_item_cosine\n",
    "\n",
    "\tif req_sim == 1:\n",
    "\t\tsim_mat_item = sim_item_jaccard\n",
    "\n",
    "\tif req_sim == 2:\n",
    "\t\tsim_mat_item = sim_item_pearson\n",
    "\n",
    "\t#predictRating(Mat, sim_mat_item)\n",
    "\treturn Mat, sim_mat_item\n",
    "\n",
    "\n",
    "def predictRating(recommend_data):\n",
    "\n",
    "\tM, sim_item = crossValidation(recommend_data)\n",
    "\n",
    "\t#f = open(\"toBeRated.csv\",\"r\")\n",
    "\tf = open(sys.argv[2],\"r\")\n",
    "\ttoBeRated = {\"user\":[], \"item\":[]}\n",
    "\tfor row in f:\n",
    "\t\tr = row.split(',')\t\n",
    "\t\ttoBeRated[\"item\"].append(int(r[1]))\n",
    "\t\ttoBeRated[\"user\"].append(int(r[0]))\n",
    "\n",
    "\tf.close()\n",
    "\n",
    "\tpred_rate = []\n",
    "\n",
    "\t#fw = open('result2.csv','w')\n",
    "\tfw_w = open('result2.csv','w')\n",
    "\n",
    "\tl = len(toBeRated[\"user\"])\n",
    "\tfor e in range(l):\n",
    "\t\tuser = toBeRated[\"user\"][e]\n",
    "\t\titem = toBeRated[\"item\"][e]\n",
    "\n",
    "\t\tpred = 3.0\n",
    "\n",
    "\t\t#item-based\n",
    "\t\tif np.count_nonzero(M[:,item-1]):\n",
    "\t\t\tsim = sim_item[item-1]\n",
    "\t\t\tind = (M[user-1] > 0)\n",
    "\t\t\t#ind[item-1] = False\n",
    "\t\t\tnormal = np.sum(np.absolute(sim[ind]))\n",
    "\t\t\tif normal > 0:\n",
    "\t\t\t\tpred = np.dot(sim,M[user-1])/normal\n",
    "\n",
    "\t\tif pred < 0:\n",
    "\t\t\tpred = 0\n",
    "\n",
    "\t\tif pred > 5:\n",
    "\t\t\tpred = 5\n",
    "\n",
    "\t\tpred_rate.append(pred)\n",
    "\t\tprint(str(user) + \",\" + str(item) + \",\" + str(pred))\n",
    "\t\t#fw.write(str(user) + \",\" + str(item) + \",\" + str(pred) + \"\\n\")\n",
    "\t\tfw_w.write(str(pred) + \"\\n\")\n",
    "\n",
    "\t#fw.close()\n",
    "\tfw_w.close()\n",
    "\n",
    "recommend_data = readingFile(\"ratings.csv\")\n",
    "# recommend_data = readingFile(sys.argv[1])\n",
    "#crossValidation(recommend_data)\n",
    "predictRating(recommend_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=title2>\n",
    "    <b><font size='3'>Hybrid</font></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-15T07:11:24.452Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello User\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.spatial\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import math\n",
    "#from sklearn.utils.extmath import np.dot\n",
    "\n",
    "users = 6040\n",
    "items = 3952\n",
    "\n",
    "def readingFile(filename):\n",
    "\tf = open(filename,\"r\")\n",
    "\tdata = []\n",
    "\tfor row in f:\n",
    "\t\tr = row.split(',')\n",
    "\t\te = [int(r[0]), int(r[1]), int(r[2])]\n",
    "\t\tdata.append(e)\n",
    "\treturn data\n",
    "\n",
    "def userData(filename):\n",
    "\tf = open(filename,\"r\")\n",
    "\tdata = np.zeros((users,3))\n",
    "\tfor row in f:\n",
    "\t\tr = row.strip().split(',')\n",
    "\t\tif r[1] == \"M\" or r[1] == \"m\":\n",
    "\t\t\tdata[int(r[0])-1] = [1,(int(r[2])/56.0),((int(r[3])+1.0)/21.0)]\n",
    "\t\telse:\n",
    "\t\t\tdata[int(r[0])-1] = [0,(int(r[2])/56.0),((int(r[3])+1)/21.0)]\n",
    "\n",
    "\treturn data\n",
    "\n",
    "\n",
    "def itemData(filename):\n",
    "\tf = open(filename,\"r\")\n",
    "\tdata = np.zeros((items,18))\n",
    "\tgenre = {\"Action\":0, \"Adventure\":1, \"Animation\":2, \"Children's\":3, \"Comedy\":4, \"Crime\":5, \"Documentary\":6, \"Drama\":7, \"Fantasy\":8, \"Film-Noir\":9, \"Horror\":10, \"Musical\":11, \"Mystery\":12, \"Romance\":13, \"Sci-Fi\":14, \"Thriller\":15, \"War\":16, \"Western\":17 }\n",
    "\tfor row in f:\n",
    "\t\tr = row.split(',')\n",
    "\t\tg = r[len(r)-1].split('|')\n",
    "\t\tfor e in g:\n",
    "\t\t\tif e.strip() not in genre.keys():\n",
    "\t\t\t\tcontinue\n",
    "\t\t\telse:\n",
    "\t\t\t\tdata[int(r[0])-1][genre[e.strip()]] = 1\n",
    "\n",
    "\treturn data\n",
    "\n",
    "def similarity_item(data):\n",
    "\tprint(\"Hello Item\")\n",
    "\t#f_i_d = open(\"sim_item_hybrid.txt\",\"w\")\n",
    "\titem_similarity_cosine = np.zeros((items,items))\n",
    "\titem_similarity_jaccard = np.zeros((items,items))\n",
    "\titem_similarity_pearson = np.zeros((items,items))\n",
    "\tfor item1 in range(items):\n",
    "\t\tprint(item1)\n",
    "\t\tfor item2 in range(items):\n",
    "\t\t\tif np.count_nonzero(data[item1]) and np.count_nonzero(data[item2]):\n",
    "\t\t\t\titem_similarity_cosine[item1][item2] = 1-scipy.spatial.distance.cosine(data[item1],data[item2])\n",
    "\t\t\t\titem_similarity_jaccard[item1][item2] = 1-scipy.spatial.distance.jaccard(data[item1],data[item2])\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tif not math.isnan(scipy.stats.pearsonr(data[item1],data[item2])[0]):\n",
    "\t\t\t\t\t\titem_similarity_pearson[item1][item2] = scipy.stats.pearsonr(data[item1],data[item2])[0]\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\titem_similarity_pearson[item1][item2] = 0\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\titem_similarity_pearson[item1][item2] = 0\n",
    "\n",
    "\t\t\t#f_i_d.write(str(item1) + \",\" + str(item2) + \",\" + str(item_similarity_cosine[item1][item2]) + \",\" + str(item_similarity_jaccard[item1][item2]) + \",\" + str(item_similarity_pearson[item1][item2]) + \"\\n\")\n",
    "\t#f_i_d.close()\n",
    "\treturn item_similarity_cosine, item_similarity_jaccard, item_similarity_pearson\n",
    "\n",
    "\n",
    "def similarity_user(data):\n",
    "\tprint(\"Hello User\")\n",
    "\t#f_i_d = open(\"sim_user_hybrid.txt\",\"w\")\n",
    "\tuser_similarity_cosine = np.zeros((users,users))\n",
    "\tuser_similarity_jaccard = np.zeros((users,users))\n",
    "\tuser_similarity_pearson = np.zeros((users,users))\n",
    "\tfor user1 in range(users):\n",
    "\t\tprint(user1)\n",
    "\t\tfor user2 in range(users):\n",
    "\t\t\tif np.count_nonzero(data[user1]) and np.count_nonzero(data[user2]):\n",
    "\t\t\t\tuser_similarity_cosine[user1][user2] = 1-scipy.spatial.distance.cosine(data[user1],data[user2])\n",
    "\t\t\t\tuser_similarity_jaccard[user1][user2] = 1-scipy.spatial.distance.jaccard(data[user1],data[user2])\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tif not math.isnan(scipy.stats.pearsonr(data[user1],data[user2])[0]):\n",
    "\t\t\t\t\t\tuser_similarity_pearson[user1][user2] = scipy.stats.pearsonr(data[user1],data[user2])[0]\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tuser_similarity_pearson[user1][user2] = 0\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tuser_similarity_pearson[user1][user2] = 0\n",
    "\n",
    "\t\t\t#f_i_d.write(str(user1) + \",\" + str(user2) + \",\" + str(user_similarity_cosine[user1][user2]) + \",\" + str(user_similarity_jaccard[user1][user2]) + \",\" + str(user_similarity_pearson[user1][user2]) + \"\\n\")\n",
    "\t#f_i_d.close()\n",
    "\treturn user_similarity_cosine, user_similarity_jaccard, user_similarity_pearson\n",
    "\n",
    "def crossValidation(data, user_data, item_data):\n",
    "\tk_fold = KFold(n_splits=10)\n",
    "\n",
    "\tsim_user_cosine, sim_user_jaccard, sim_user_pearson = similarity_user(user_data)\n",
    "\tsim_item_cosine, sim_item_jaccard, sim_item_pearson = similarity_item(item_data)\n",
    "\t#sim_user_cosine, sim_user_jaccard, sim_user_pearson = np.random.rand(users,users), np.random.rand(users,users), np.random.rand(users,users)\n",
    "\t#sim_item_cosine, sim_item_jaccard, sim_item_pearson = np.random.rand(items,items), np.random.rand(items,items), np.random.rand(items,items) \n",
    "\n",
    "\t'''sim_user_cosine = np.zeros((users,users))\n",
    "\tsim_user_jaccard = np.zeros((users,users))\n",
    "\tsim_user_pearson = np.zeros((users,users))\n",
    "\n",
    "\tf_sim = open(\"sim_user_hybrid.txt\", \"r\")\n",
    "\tfor row in f_sim:\n",
    "\t\t#print row\n",
    "\t\tr = row.strip().split(',')\n",
    "\t\tsim_user_cosine[int(r[0])][int(r[1])] = float(r[2])\n",
    "\t\tsim_user_jaccard[int(r[0])][int(r[1])] = float(r[3])\n",
    "\t\tsim_user_pearson[int(r[0])][int(r[1])] = float(r[4])\n",
    "\tf_sim.close()\n",
    "\n",
    "\n",
    "\tsim_item_cosine = np.zeros((items,items))\n",
    "\tsim_item_jaccard = np.zeros((items,items))\n",
    "\tsim_item_pearson = np.zeros((items,items))\n",
    "\n",
    "\tf_sim_i = open(\"sim_item_hybrid.txt\", \"r\")\n",
    "\tfor row in f_sim_i:\n",
    "\t\t#print row\n",
    "\t\tr = row.strip().split(',')\n",
    "\t\tsim_item_cosine[int(r[0])][int(r[1])] = float(r[2])\n",
    "\t\tsim_item_jaccard[int(r[0])][int(r[1])] = float(r[3])\n",
    "\t\tsim_item_pearson[int(r[0])][int(r[1])] = float(r[4])\n",
    "\tf_sim_i.close()'''\n",
    "\n",
    "\trmse_cosine = []\n",
    "\trmse_jaccard = []\n",
    "\trmse_pearson = []\n",
    "\n",
    "\tfor train_indices, test_indices in k_fold:\n",
    "\t\ttrain = [data[i] for i in train_indices]\n",
    "\t\ttest = [data[i] for i in test_indices]\n",
    "\n",
    "\t\tM = np.zeros((users,items))\n",
    "\n",
    "\t\tfor e in train:\n",
    "\t\t\tM[e[0]-1][e[1]-1] = e[2]\n",
    "\n",
    "\t\ttrue_rate = []\n",
    "\t\tpred_rate_cosine = []\n",
    "\t\tpred_rate_jaccard = []\n",
    "\t\tpred_rate_pearson = []\n",
    "\n",
    "\t\tfor e in test:\n",
    "\t\t\tuser = e[0]\n",
    "\t\t\titem = e[1]\n",
    "\t\t\ttrue_rate.append(e[2])\n",
    "\n",
    "\t\t\tuser_pred_cosine = 3.0\n",
    "\t\t\titem_pred_cosine = 3.0\n",
    "\n",
    "\t\t\tuser_pred_jaccard = 3.0\n",
    "\t\t\titem_pred_jaccard = 3.0\n",
    "\n",
    "\t\t\tuser_pred_pearson = 3.0\n",
    "\t\t\titem_pred_pearson = 3.0\n",
    "\n",
    "\t\t\t#item-based\n",
    "\t\t\tif np.count_nonzero(M[:,item-1]):\n",
    "\t\t\t\tsim_cosine = sim_item_cosine[item-1]\n",
    "\t\t\t\tsim_jaccard = sim_item_jaccard[item-1]\n",
    "\t\t\t\tsim_pearson = sim_item_pearson[item-1]\n",
    "\t\t\t\tind = (M[user-1] > 0)\n",
    "\t\t\t\t#ind[item-1] = False\n",
    "\t\t\t\tnormal_cosine = np.sum(np.absolute(sim_cosine[ind]))\n",
    "\t\t\t\tnormal_jaccard = np.sum(np.absolute(sim_jaccard[ind]))\n",
    "\t\t\t\tnormal_pearson = np.sum(np.absolute(sim_pearson[ind]))\n",
    "\t\t\t\tif normal_cosine > 0:\n",
    "\t\t\t\t\titem_pred_cosine = np.dot(sim_cosine,M[user-1])/normal_cosine\n",
    "\n",
    "\t\t\t\tif normal_jaccard > 0:\n",
    "\t\t\t\t\titem_pred_jaccard = np.dot(sim_jaccard,M[user-1])/normal_jaccard\n",
    "\n",
    "\t\t\t\tif normal_pearson > 0:\n",
    "\t\t\t\t\titem_pred_pearson = np.dot(sim_pearson,M[user-1])/normal_pearson\n",
    "\n",
    "\t\t\tif item_pred_cosine < 0:\n",
    "\t\t\t\titem_pred_cosine = 0\n",
    "\n",
    "\t\t\tif item_pred_cosine > 5:\n",
    "\t\t\t\titem_pred_cosine = 5\n",
    "\n",
    "\t\t\tif item_pred_jaccard < 0:\n",
    "\t\t\t\titem_pred_jaccard = 0\n",
    "\n",
    "\t\t\tif item_pred_jaccard > 5:\n",
    "\t\t\t\titem_pred_jaccard = 5\n",
    "\n",
    "\t\t\tif item_pred_pearson < 0:\n",
    "\t\t\t\titem_pred_pearson = 0\n",
    "\n",
    "\t\t\tif item_pred_pearson > 5:\n",
    "\t\t\t\titem_pred_pearson = 5\n",
    "\n",
    "\t\t\t#user-based\n",
    "\t\t\tif np.count_nonzero(M[user-1]):\n",
    "\t\t\t\tsim_cosine = sim_user_cosine[user-1]\n",
    "\t\t\t\tsim_jaccard = sim_user_jaccard[user-1]\n",
    "\t\t\t\tsim_pearson = sim_user_pearson[user-1]\n",
    "\t\t\t\tind = (M[:,item-1] > 0)\n",
    "\t\t\t\t#ind[user-1] = False\n",
    "\t\t\t\tnormal_cosine = np.sum(np.absolute(sim_cosine[ind]))\n",
    "\t\t\t\tnormal_jaccard = np.sum(np.absolute(sim_jaccard[ind]))\n",
    "\t\t\t\tnormal_pearson = np.sum(np.absolute(sim_pearson[ind]))\n",
    "\t\t\t\tif normal_cosine > 0:\n",
    "\t\t\t\t\tuser_pred_cosine = np.dot(sim_cosine,M[:,item-1])/normal_cosine\n",
    "\n",
    "\t\t\t\tif normal_jaccard > 0:\n",
    "\t\t\t\t\tuser_pred_jaccard = np.dot(sim_jaccard,M[:,item-1])/normal_jaccard\n",
    "\n",
    "\t\t\t\tif normal_pearson > 0:\n",
    "\t\t\t\t\tuser_pred_pearson = np.dot(sim_pearson,M[:,item-1])/normal_pearson\n",
    "\n",
    "\t\t\tif user_pred_cosine < 0:\n",
    "\t\t\t\tuser_pred_cosine = 0\n",
    "\n",
    "\t\t\tif user_pred_cosine > 5:\n",
    "\t\t\t\tuser_pred_cosine = 5\n",
    "\n",
    "\t\t\tif user_pred_jaccard < 0:\n",
    "\t\t\t\tuser_pred_jaccard = 0\n",
    "\n",
    "\t\t\tif user_pred_jaccard > 5:\n",
    "\t\t\t\tuser_pred_jaccard = 5\n",
    "\n",
    "\t\t\tif user_pred_pearson < 0:\n",
    "\t\t\t\tuser_pred_pearson = 0\n",
    "\n",
    "\t\t\tif user_pred_pearson > 5:\n",
    "\t\t\t\tuser_pred_pearson = 5\n",
    "\n",
    "\t\t\tif (user_pred_cosine != 0 and user_pred_cosine != 5) and (item_pred_cosine != 0 and item_pred_cosine != 5):\n",
    "\t\t\t\tpred_cosine = (user_pred_cosine + item_pred_cosine)/2\n",
    "\t\t\telse:\n",
    "\t\t\t\tif (user_pred_cosine == 0 or user_pred_cosine == 5):\n",
    "\t\t\t\t\tif (item_pred_cosine != 0 and item_pred_cosine != 5):\n",
    "\t\t\t\t\t\tpred_cosine = item_pred_cosine\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tpred_cosine = 3.0\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tif (user_pred_cosine != 0 and user_pred_cosine != 5):\n",
    "\t\t\t\t\t\tpred_cosine = user_pred_cosine\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tpred_cosine = 3.0\n",
    "\n",
    "\t\t\tif (user_pred_jaccard != 0 and user_pred_jaccard != 5) and (item_pred_jaccard != 0 and item_pred_jaccard != 5):\n",
    "\t\t\t\tpred_jaccard = (user_pred_jaccard + item_pred_jaccard)/2\n",
    "\t\t\telse:\n",
    "\t\t\t\tif (user_pred_jaccard == 0 or user_pred_jaccard == 5):\n",
    "\t\t\t\t\tif (item_pred_jaccard != 0 and item_pred_jaccard != 5):\n",
    "\t\t\t\t\t\tpred_jaccard = item_pred_jaccard\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tpred_jaccard = 3.0\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tif (user_pred_jaccard != 0 and user_pred_jaccard != 5):\n",
    "\t\t\t\t\t\tpred_jaccard = user_pred_jaccard\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tpred_jaccard = 3.0\n",
    "\n",
    "\t\t\tif (user_pred_pearson != 0 and user_pred_pearson != 5) and (item_pred_pearson != 0 and item_pred_pearson != 5):\n",
    "\t\t\t\tpred_pearson = (user_pred_pearson + item_pred_pearson)/2\n",
    "\t\t\telse:\n",
    "\t\t\t\tif (user_pred_pearson == 0 or user_pred_pearson == 5):\n",
    "\t\t\t\t\tif (item_pred_pearson != 0 and item_pred_pearson != 5):\n",
    "\t\t\t\t\t\tpred_pearson = item_pred_pearson\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tpred_pearson = 3.0\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tif (user_pred_pearson != 0 and user_pred_pearson != 5):\n",
    "\t\t\t\t\t\tpred_pearson = user_pred_pearson\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tpred_pearson = 3.0\n",
    "\t\t\t\n",
    "\t\t\t#pred_cosine = (user_pred_cosine + item_pred_cosine)/2\n",
    "\t\t\t#pred_jaccard = (user_pred_jaccard + item_pred_jaccard)/2\n",
    "\t\t\t#pred_pearson = (user_pred_pearson + item_pred_pearson)/2\n",
    "\t\t\tprint(str(user) + \"\\t\" + str(item) + \"\\t\" + str(e[2]) + \"\\t\" + str(pred_cosine) + \"\\t\" + str(pred_jaccard) + \"\\t\" + str(pred_pearson))\n",
    "\t\t\tpred_rate_cosine.append(pred_cosine)\n",
    "\t\t\tpred_rate_jaccard.append(pred_jaccard)\n",
    "\t\t\tpred_rate_pearson.append(pred_pearson)\n",
    "\n",
    "\t\t#print len(true_rate)\n",
    "\t\t#print len(pred_rate_cosine)\n",
    "\t\trmse_cosine.append(sqrt(mean_squared_error(true_rate, pred_rate_cosine)))\n",
    "\t\trmse_jaccard.append(sqrt(mean_squared_error(true_rate, pred_rate_jaccard)))\n",
    "\t\trmse_pearson.append(sqrt(mean_squared_error(true_rate, pred_rate_pearson)))\n",
    "\n",
    "\t\tprint(str(sqrt(mean_squared_error(true_rate, pred_rate_cosine))) + \"\\t\" + str(sqrt(mean_squared_error(true_rate, pred_rate_jaccard))) + \"\\t\" + str(sqrt(mean_squared_error(true_rate, pred_rate_pearson))))\n",
    "\t\t#raw_input()\n",
    "\n",
    "\t#print sum(rms) / float(len(rms))\n",
    "\trmse_cosine = sum(rmse_cosine) / float(len(rmse_cosine))\n",
    "\trmse_pearson = sum(rmse_pearson) / float(len(rmse_pearson))\n",
    "\trmse_jaccard = sum(rmse_jaccard) / float(len(rmse_jaccard))\n",
    "\n",
    "\tprint(str(rmse_cosine) + \"\\t\" + str(rmse_jaccard) + \"\\t\" + str(rmse_pearson))\n",
    "\n",
    "\tf_rmse = open(\"rmse_hybrid.txt\",\"w\")\n",
    "\tf_rmse.write(str(rmse_cosine) + \"\\t\" + str(rmse_jaccard) + \"\\t\" + str(rmse_pearson) + \"\\n\")\n",
    "\n",
    "\trmse = [rmse_cosine, rmse_jaccard, rmse_pearson]\n",
    "\treq_sim = rmse.index(min(rmse))\n",
    "\n",
    "\tprint(req_sim)\n",
    "\tf_rmse.write(str(req_sim))\n",
    "\tf_rmse.close()\n",
    "\n",
    "\tif req_sim == 0:\n",
    "\t\tsim_mat_user = sim_user_cosine\n",
    "\t\tsim_mat_item = sim_item_cosine\n",
    "\n",
    "\tif req_sim == 1:\n",
    "\t\tsim_mat_user = sim_user_jaccard\n",
    "\t\tsim_mat_item = sim_item_jaccard\n",
    "\n",
    "\tif req_sim == 2:\n",
    "\t\tsim_mat_user = sim_user_pearson\n",
    "\t\tsim_mat_item = sim_item_pearson\n",
    "\n",
    "\t#predictRating(data, sim_mat_user, sim_mat_item)\n",
    "\treturn sim_mat_user, sim_mat_item\n",
    "\n",
    "\n",
    "def predictRating(data, user_data, item_data):\n",
    "\n",
    "\tsim_user, sim_item = crossValidation(data, user_data, item_data)\n",
    "\n",
    "\tM = np.zeros((users,items))\n",
    "\tfor e in data:\n",
    "\t\tM[e[0]-1][e[1]-1] = e[2]\n",
    "\n",
    "\t#f = open(\"toBeRated.csv\",\"r\")\n",
    "\tf = open(sys.argv[2],\"r\")\t\n",
    "\ttoBeRated = {\"user\":[], \"item\":[]}\n",
    "\tfor row in f:\n",
    "\t\tr = row.split(',')\t\n",
    "\t\ttoBeRated[\"item\"].append(int(r[1]))\n",
    "\t\ttoBeRated[\"user\"].append(int(r[0]))\n",
    "\n",
    "\tf.close()\n",
    "\n",
    "\tpred_rate = []\n",
    "\n",
    "\t#fw = open('result3.csv','w')\n",
    "\tfw_w = open('result3.csv','w')\n",
    "\n",
    "\tl = len(toBeRated[\"user\"])\n",
    "\tfor e in range(l):\n",
    "\t\tuser = toBeRated[\"user\"][e]\n",
    "\t\titem = toBeRated[\"item\"][e]\n",
    "\n",
    "\t\tuser_pred = 3.0\n",
    "\t\titem_pred = 3.0\n",
    "\n",
    "\t\t#item-based\n",
    "\t\tif np.count_nonzero(M[:,item-1]):\n",
    "\t\t\tsim = sim_item[item-1]\n",
    "\t\t\tind = (M[user-1] > 0)\n",
    "\t\t\t#ind[item-1] = False\n",
    "\t\t\tnormal = np.sum(np.absolute(sim[ind]))\n",
    "\t\t\tif normal > 0:\n",
    "\t\t\t\titem_pred = np.dot(sim,M[user-1])/normal\n",
    "\n",
    "\t\tif item_pred < 0:\n",
    "\t\t\titem_pred = 0\n",
    "\n",
    "\t\tif item_pred > 5:\n",
    "\t\t\titem_pred = 5\n",
    "\n",
    "\t\t#user-based\n",
    "\t\tif np.count_nonzero(M[user-1]):\n",
    "\t\t\tsim = sim_user[user-1]\n",
    "\t\t\tind = (M[:,item-1] > 0)\n",
    "\t\t\t#ind[user-1] = False\n",
    "\t\t\tnormal = np.sum(np.absolute(sim[ind]))\n",
    "\t\t\tif normal > 0:\n",
    "\t\t\t\tuser_pred = np.dot(sim,M[:,item-1])/normal\n",
    "\n",
    "\t\tif user_pred < 0:\n",
    "\t\t\tuser_pred = 0\n",
    "\n",
    "\t\tif user_pred > 5:\n",
    "\t\t\tuser_pred = 5\n",
    "\n",
    "\t\tif (user_pred != 0 and user_pred != 5) and (item_pred != 0 and item_pred != 5):\n",
    "\t\t\t\tpred = (user_pred + item_pred)/2\n",
    "\t\telse:\n",
    "\t\t\tif (user_pred == 0 or user_pred == 5):\n",
    "\t\t\t\tif (item_pred != 0 and item_pred != 5):\n",
    "\t\t\t\t\tpred = item_pred\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tpred = 3.0\n",
    "\t\t\telse:\n",
    "\t\t\t\tif (user_pred != 0 and user_pred != 5):\n",
    "\t\t\t\t\tpred = user_pred\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tpred = 3.0\n",
    "\n",
    "\t\t#pred = (user_pred + item_pred)/2\n",
    "\t\tpred_rate.append(pred)\n",
    "\t\tprint(str(user) + \",\" + str(item) + \",\" + str(pred))\n",
    "\t\t#fw.write(str(user) + \",\" + str(item) + \",\" + str(pred) + \"\\n\")\n",
    "\t\tfw_w.write(str(pred) + \"\\n\")\n",
    "\n",
    "\t#fw.close()\n",
    "\tfw_w.close()\n",
    "\n",
    "recommend_data = readingFile(\"ratings.csv\")\n",
    "# recommend_data = readingFile(sys.argv[1])\n",
    "user_data = userData(\"users.csv\")\n",
    "item_data = itemData(\"movies.csv\")\n",
    "predictRating(recommend_data, user_data, item_data)\n",
    "#crossValidation(recommend_data, user_data, item_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
