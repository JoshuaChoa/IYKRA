{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=title>\n",
    "<strong><center><font size=\"3\">DAY 7 - IYKRA</font></center>\n",
    "<hr>\n",
    "<center><font size=\"5\"><strong>Practice Case 02</strong></font></center>\n",
    "<center><font size=\"4\"><strong>Exploratory Data Analysis (EDA) Use Case</strong></font></center>\n",
    "<hr>\n",
    "<p style=\"text-align:center\">Author</p>\n",
    "<center>Joshua Effendi</center>\n",
    "<p style=\"text-align:center\">Date:</p>\n",
    "<center>29 October 2019</center></strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><strong>Practice Case 2</strong></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "%matplotlib inline\n",
    "import scipy.stats as sct\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cluster\n",
    "import plotly.offline as py\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"./styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><strong>Questions</strong></font>\n",
    "1. Describe each columns (data types, unique values/range of values, missing values, etc.)\n",
    "2. Is the data fit for analysis? If not, what wrangling steps should be done?\n",
    "3. From the data, what can you describe about their sample of customers?\n",
    "4. Are they potentially “lucrative” customers? If so, how many of them are and why?\n",
    "5. What are the difference between customers who are interested in the product and those who don’t?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank-marketing-full.csv',sep=';')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><strong>Data Describe Types</strong></font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=cbox>\n",
    "<strong>As seen above, there are three types of data divided into two groups, which is numerical data in which consist of float and integer data and categorical data in which consist of object. There are 10 numerical features divided into <font color=\"red\">5 Float</font> and <font color=\"red\">5 Integer</font>. Lastly there are 11 categorical data in which data type is <font color=\"red\">Object</font></strong>\n",
    "</div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,pd.get_dummies(df['y'], prefix = 'bool').drop(columns='bool_no')], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=cbox>\n",
    "    <b>Add numerical data for y feature to <font color='red'>boolean</font> to accomodate the correlation figure.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = df.select_dtypes(include = [np.number]).columns\n",
    "categorical_data = df.select_dtypes(exclude = [np.number]).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"2\"><strong>Divide the columns by it's type, categorical and numerical.</strong></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><strong>Data Range/Unique Values</strong></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numerical_data].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=cbox>\n",
    "<b>As seen above is the data descriptions for the numerical data and also the <font color='red'>range</font> of the data</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical_data].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=cbox>\n",
    "<b>As seen above is the data descriptions for the categorical data and also the <font color='red'>unique</font> values of the data.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><strong>Missing Values</stong></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=cbox>\n",
    "    <b>No missing values in the data as no need to manipulate the data for the missing values. Except the 999 in data as it is stated as missing values.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Normalized Relative Frequency of Target</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in categorical_data:\n",
    "    plt.figure(figsize=(10,4))\n",
    "    \n",
    "    pos_counts = df.loc[df.y.values == 'yes', col].value_counts() \n",
    "    neg_counts = df.loc[df.y.values == 'no', col].value_counts()\n",
    "    \n",
    "    all_counts = list(set(list(pos_counts.index) + list(neg_counts.index)))\n",
    "    \n",
    "    freq_pos = (df.y.values == 'yes').sum()\n",
    "    freq_neg = (df.y.values == 'no').sum()\n",
    "    \n",
    "    pos_counts = pos_counts.to_dict()\n",
    "    neg_counts = neg_counts.to_dict()\n",
    "    \n",
    "    all_index = list(all_counts)\n",
    "    all_counts = [pos_counts.get(k, 0) / freq_pos - neg_counts.get(k, 0) / freq_neg for k in all_counts]\n",
    "\n",
    "    sns.barplot(all_counts, all_index)\n",
    "    plt.title(col)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=cbox>\n",
    "    <b>There are a lot of unknown data in which have to be handled.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><strong>Imputation Data - Inferring</strong></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cat_dat = ['education','job','housing','loan']\n",
    "for var in s_cat_dat:\n",
    "    df[var + '_un'] = (df[var] == 'unknown').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_tab(df,f1,f2):\n",
    "    jobs=list(df[f1].unique())\n",
    "    edu=list(df[f2].unique())\n",
    "    dataframes=[]\n",
    "    for e in edu:\n",
    "        dfe=df[df[f2]==e]\n",
    "        dfejob=dfe.groupby(f1).count()[f2]\n",
    "        dataframes.append(dfejob)\n",
    "    xx=pd.concat(dataframes,axis=1)\n",
    "    xx.columns=edu\n",
    "    xx=xx.fillna(0)\n",
    "    return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab(df,'job','education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job'][df['age']>60].value_counts().reset_index().set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=cbox>\n",
    "    <b>Inferring: Education, From: Job. From the cross-tabulation data we can infer that people with management job usually have an university education background, similarly with service and high school and housemaid with basic.4y.\n",
    "<hr>\n",
    "    Inferring: Job, From: Education. Education of basic.4y, basic.6y, and basic.9y usually have a job blue-collar, similarly with professional.course have a job of technician.\n",
    "<hr>\n",
    "    Inferring: Job, From: Age. People with age more than 60 years old have a retired job. </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Replace Data with the Cross-tab Data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['age']>60) & (df['job']=='unknown'), 'job'] = 'retired'\n",
    "df.loc[(df['education']=='unknown') & (df['job']=='management'), 'education'] = 'university.degree'\n",
    "df.loc[(df['education']=='unknown') & (df['job']=='services'), 'education'] = 'high.school'\n",
    "df.loc[(df['education']=='unknown') & (df['job']=='housemaid'), 'education'] = 'basic.4y'\n",
    "df.loc[(df['job'] == 'unknown') & (df['education']=='basic.4y'), 'job'] = 'blue-collar'\n",
    "df.loc[(df['job'] == 'unknown') & (df['education']=='basic.6y'), 'job'] = 'blue-collar'\n",
    "df.loc[(df['job'] == 'unknown') & (df['education']=='basic.9y'), 'job'] = 'blue-collar'\n",
    "df.loc[(df['job']=='unknown') & (df['education']=='professional.course'), 'job'] = 'technician'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Check cross-tab Job and Housing, Loan</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab(df,'job','housing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=cbox>\n",
    "    <b>It has similar split between yes and no in house by jobs.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab(df,'job','loan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=cbox>\n",
    "    <b>We can further clean the data by looking at the cross-tab of job and loan.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillhousing(df,jobhousing):\n",
    "    jobs=['housemaid','services','admin.','blue-collar','technician','retired','management','unemployed','self-employed','entrepreneur','student']\n",
    "    house=[\"no\",\"yes\"]\n",
    "    for j in jobs:\n",
    "        ind=df[np.logical_and(np.array(df['housing']=='unknown'),np.array(df['job']==j))].index\n",
    "        mask=np.random.rand(len(ind))<((jobhousing.loc[j]['no'])/(jobhousing.loc[j]['no']+jobhousing.loc[j]['yes']))\n",
    "        ind1=ind[mask]\n",
    "        ind2=ind[~mask]\n",
    "        df.loc[ind1,\"housing\"]='no'\n",
    "        df.loc[ind2,\"housing\"]='yes'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillloan(df,jobloan):\n",
    "    jobs=['housemaid','services','admin.','blue-collar','technician','retired','management','unemployed','self-employed','entrepreneur','student']\n",
    "    loan=[\"no\",\"yes\"]\n",
    "    for j in jobs:\n",
    "        ind=df[np.logical_and(np.array(df['loan']=='unknown'),np.array(df['job']==j))].index\n",
    "        mask=np.random.rand(len(ind))<((jobloan.loc[j]['no'])/(jobloan.loc[j]['no']+jobloan.loc[j]['yes']))\n",
    "        ind1=ind[mask]\n",
    "        ind2=ind[~mask]\n",
    "        df.loc[ind1,\"loan\"]='no'\n",
    "        df.loc[ind2,\"loan\"]='yes'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobhousing=cross_tab(df,'job','housing')\n",
    "jobloan=cross_tab(df,'job','loan')\n",
    "df=fillhousing(df,jobhousing)\n",
    "df=fillloan(df,jobloan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Numerical Data Imputation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Missing values for pdays for 999</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['pdays'],df['poutcome'], values=df['age'], aggfunc='count', normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=cbox>\n",
    "    <b>It is better to have a categorical data for pdays.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pdays_missing'] = 0\n",
    "df['pdays_less_5'] = 0\n",
    "df['pdays_greater_15'] = 0\n",
    "df['pdays_bet_5_15'] = 0\n",
    "df['pdays_missing'][df['pdays'] == 999] = 1\n",
    "df['pdays_less_5'][df['pdays']<5] = 1\n",
    "df['pdays_greater_15'][(df['pdays'] > 15) & (df['pdays'] < 999)] = 1\n",
    "df['pdays_bet_5_15'][(df['pdays'] >= 5) & (df['pdays'] <= 15)]= 1\n",
    "df_pdays_d = df.drop('pdays', axis=1)\n",
    "df_pdays_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dum = pd.get_dummies(df_pdays_d)\n",
    "df_dum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropfeature(df,f):\n",
    "    df=df.drop(f,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dropped = ['default_no','housing_no','loan_no','y_no','marital_single','contact_cellular',\n",
    "                    'education_unknown','job_unknown','housing_unknown','loan_unknown', 'pdays_less_5']\n",
    "df_clean = dropfeature(df_dum, features_dropped)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = df.select_dtypes(include = [np.number]).columns\n",
    "categorical_data = df.select_dtypes(exclude = [np.number]).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><strong>Data Fitting for Analysis</strong></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>There are features in which have outliers data, that need to be adjusted.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numerical_data:\n",
    "    print(\"IQR for feature {} is {} with minimal value allowed is {} and maximal value allowed is {}.\\\n",
    "    \".format(i.upper(), np.round(sct.iqr(df[i]),2), np.round(df[i].quantile(0.25) - 1.5 * sct.iqr(df[i]),2), \\\n",
    "             np.round(df[i].quantile(0.75) + 1.5 * sct.iqr(df[i]),2)))\n",
    "    print('Minimal value of data: {} and Maximal value of data: {}\\n'.format(np.round(df[i].min(),2), \\\n",
    "                                                                             np.round(df[i].max(),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=cbox>\n",
    "    <b>As seen from above, there are lots of data in which are outlier so we need to do some cleansing</b>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><strong>Data Numerical Correlation for Analysis</strong></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr = df.corr(method = 'pearson')\n",
    "mask = np.array(corr)\n",
    "mask[np.tril_indices_from(mask)] = False\n",
    "fig, ax = plt.subplots(figsize = (20,18))\n",
    "fig.set_size_inches(20,20)\n",
    "sns.heatmap(corr, mask = mask, vmax = 0.9, square = True, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=cbox>\n",
    "    <b>As seen the heatmap graph, there are multiple correality, it is wise to avoid features with high correality for modeling</b>\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.abs(df.corr(method= 'pearson')['bool_yes']).sort_values(ascending=False)[1:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=cbox>\n",
    "    <b>As seen above, the highest result of correlation for target bool_yes is duration. We could create models with these features, but as there are multiple correality in the features, it is wise to drop on some features to avoid high correality</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><strong>Explanatory Data Analysis</stong></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Categorical Data Plot</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in categorical_data:\n",
    "    plt.figure(figsize=(10,4))\n",
    "    sns.barplot(df[col].value_counts().values, df[col].value_counts().index)\n",
    "    plt.title(col)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Numerical Data Plot</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in numerical_data:\n",
    "    if len(df[col].unique()) <= 5:\n",
    "        bin1 = 2\n",
    "    elif len(df[col].unique()) <= 10:\n",
    "        bin1 = 5\n",
    "    elif len(df[col].unique()) <= 50:\n",
    "        bin1 = 10\n",
    "    else:\n",
    "        bin1 = 100\n",
    "    fig = px.histogram(df, x = col, nbins=bin1)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data_c = df_clean.select_dtypes(include = [np.number]).columns\n",
    "categorical_data_c = df_clean.select_dtypes(exclude = [np.number]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in numerical_data_c:\n",
    "    if len(df_clean[col].unique()) <= 5:\n",
    "        bin1 = 2\n",
    "    elif len(df_clean[col].unique()) <= 10:\n",
    "        bin1 = 5\n",
    "    elif len(df_clean[col].unique()) <= 50:\n",
    "        bin1 = 10\n",
    "    else:\n",
    "        bin1 = 100\n",
    "    fig = px.histogram(df_clean, x = col, nbins=bin1)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Cluster Data</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = df[['age','nr.employed']].as_matrix()\n",
    "combined_data_scaled = preprocessing.scale(combined_data)\n",
    "\n",
    "kmeans = cluster.KMeans(n_clusters = 3)\n",
    "kmeans.fit(combined_data_scaled)\n",
    "y_pred = kmeans.predict(combined_data_scaled)\n",
    "\n",
    "plt.scatter(combined_data_scaled[:, 0], combined_data_scaled[:, 1], c = y_pred)\n",
    "plt.xlabel('Scaled Age')\n",
    "plt.ylabel('Scaled  number of employees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=cbox>\n",
    "    <b>The graph shows the cluster of age range and particular job employee.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Plot Divide Boolean Yes</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in categorical_data:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.countplot(x=col,data=df,hue='y')\n",
    "    plt.title(col)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3'><b>Data Analysis</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=cbox>\n",
    "    <b>The sample data is not good enough as there are lots of unknown data and need to be engineer to be a good sample data.\n",
    "<hr>\n",
    "    There are always \"lucrative\" customers as there are lot of potential customer even though the majority of the customers are saying no. But as we do not know the current income of the customers we could not really say that if that customers are really lucrative or not. As lucrative also based on the customers risk also and the data there is not any info for customers' risk, so we could not also infer if they are lucrative or not. But if could create a model, we could tell the lucrative customers but as this is only EDA, so there is no model.\n",
    "<hr>    \n",
    "    From the data we can infer that customers whom are married that own a house and their poutcome are non-existence has a higher chance of saying yes. Also customers that have a success previously had a higher chance to say yes also. Based on percentage, customers whom had technician as their job had a higer chance also to say yes.</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
